{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation and Grouping\n",
    "## Using World Flags Data\n",
    "\n",
    "<img src='flags.JPG'>\n",
    "\n",
    "A critical task for data analysis is often aggregating or transforming groups of data. After preparing your data, you may need to compute group statistics or possible pivot tables for reporting or visualization purposes. Pandas `groupby` is a flexible way to perform these aggregations and summarize datasets.\n",
    "\n",
    "For this module, we will be working with data that contains details of various nations and their flags. It was originally collected from the 'Collins Gen Guide to Flags' from Collins Publishers in 1986. Note that this data is out-of-date. For instance, it still includes 'USSR' as a country.\n",
    "      \n",
    "Here is some basic information about the dataset:\n",
    "\n",
    "- There are 194 instances (aka rows).\n",
    "- There are 30 attributes in total (aka columns).\n",
    "- 10 attributes are numeric-valued.  The remainder are either Boolean or nominal-valued.\n",
    "- There are no missing values.\n",
    "\n",
    "**Attribute Information**\n",
    "\n",
    "1. name: Name of the country concerned\n",
    "2. landmass: 1=N.America, 2=S.America, 3=Europe, 4=Africa, 5=Asia, 6=Oceania\n",
    "3. zone: Geographic quadrant, based on Greenwich and the Equator (1=NE, 2=SE, 3=SW, 4=NW)\n",
    "4. area: in thousands of square km\n",
    "5. population: in round millions\n",
    "6. language: 1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic,            9=Japanese/Turkish/Finnish/Magyar, 10=Others\n",
    "7. religion: 0=Catholic, 1=Other Christian, 2=Muslim, 3=Buddhist, 4=Hindu, 5=Ethnic, 6=Marxist, 7=Others\n",
    "8. bars: Number of vertical bars in the flag\n",
    "9. stripes: Number of horizontal stripes in the flag\n",
    "10. colors: Number of different colors in the flag\n",
    "11. red: 0 if red absent, 1 if red present in the flag\n",
    "12. green: same for green\n",
    "13. blue: same for blue\n",
    "14. gold: same for gold (also yellow)\n",
    "15. white: same for white\n",
    "16. black: same for black\n",
    "17. orange: same for orange (also brown)\n",
    "18. mainhue: predominant colour in the flag (tie-breaks decided by taking the topmost hue, if that fails then the most central hue, and if that fails the leftmost hue)\n",
    "19. circles: Number of circles in the flag\n",
    "20. crosses: Number of (upright) crosses\n",
    "21. saltires: Number of diagonal crosses\n",
    "22. quarters: Number of quartered sections\n",
    "23. sunstars: Number of sun or star symbols\n",
    "24. crescent: 1 if a crescent moon symbol present, else 0\n",
    "25. triangle: 1 if any triangles present, 0 otherwise\n",
    "26. icon: 1 if an inanimate image present (e.g., a boat), otherwise 0\n",
    "27. animate: 1 if an animate image (e.g., an eagle, a tree, a human hand) present, 0 otherwise\n",
    "28. text: 1 if any letters or writing on the flag (e.g., a motto or slogan), 0 otherwise\n",
    "29. topleft: color in the top-left corner (moving right to decide tie-breaks)\n",
    "30. botright: color in the bottom-left corner (moving left to decide tie-breaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Exploration of Flags Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of column names\n",
    "columns = ['name','landmass','zone','area','population','language','religion','num_bars','num_stripes','num_colors',\n",
    "           'red','green','blue','gold','white','black','orange','mainhue','num_circles','num_crosses','num_saltires',\n",
    "           'num_quarters','num_sunstars','crescent','triangle','icon','animate','text','topleft_color','botright_color']\n",
    "\n",
    "# import data and show first five rows\n",
    "flags = pd.read_csv('flag.data', names=columns)\n",
    "flags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check size of dataset\n",
    "flags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check general information about dataset\n",
    "flags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check general statistical information\n",
    "flags.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy Mechanics\n",
    "### Basic Grouping\n",
    "\n",
    "Hadley Wickham, an author of many popular packages for the R programming language, coined the term split-apply-combine for describing group operations. \n",
    "\n",
    "- First, the data is split into groups.\n",
    "- Second, a function is applied to each group\n",
    "- Finally, the results are combined into a result object\n",
    "\n",
    "Here is a mockup of a simple group aggregation.\n",
    "\n",
    "<img src='split_apply_combine.JPG'>\n",
    "\n",
    "*Hadley Wickham, an author of many popular packages for the R programming language, coined the term split-apply-combine for describing group operations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, let's create a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample dataset with random data\n",
    "df = pd.DataFrame({'studio_key' : ['Marvel', 'Marvel', 'DC', 'DC', 'Marvel'],\n",
    "     'department_key' : ['Production', 'Advertising', 'Production', 'Advertising', 'Production'],\n",
    "     'data1' : [10,6,2,7,5],\n",
    "     'data2' : [-1,4,-6,5,11]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to compute the mean of `data1` grouped by the `studio_key` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Series GroupBy object using 'studio_key'\n",
    "grouped = df['data1'].groupby(df['studio_key'])\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply call the 'mean' method on the GroupBy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces new Series\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining it all together\n",
    "grouped = df['data1'].groupby(df['studio_key']).mean()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily pass multiple keys to be used by the GroupBy object. This actually creates a multi-index Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing multiple Series as a list\n",
    "means = df['data1'].groupby([df['studio_key'], df['department_key']]).mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you can use `unstack()` to produce a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using unstack() to create a DataFrame\n",
    "means.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently the grouping information is found in the same DataFrame as the data you want to work on. In that case, you can pass column names  as the group keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing DataFrame column names as group keys\n",
    "df.groupby('studio_key').mean()\n",
    "\n",
    "# df['data1'].groupby('studio_key').mean() #produces error\n",
    "# df['data1'].groupby(df['studio_key']).mean() #produces Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is no `department_key` in the above result. Since that column is not numeric, it is excluded from the result. By default, all of the numeric columns are aggregated, though it is possible to filter down to a subset as we will soon see.\n",
    "\n",
    "A very useful GroupBy method is `size`, which returns a Series containing group sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show group sizes\n",
    "df.groupby(['studio_key', 'department_key']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Practice\n",
    "Try to perform the following tasks on the `flags` dataset. Then check your answers as I walk through the solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Instantiate (create) a SeriesGroupBy object called `grouped_flags` that selects `population` from the `flags` dataset and groups it by `landmass`\n",
    "\n",
    "*Note: landmass: 1=N.America, 2=S.America, 3=Europe, 4=Africa, 5=Asia, 6=Oceania*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using the `grouped_flags` object, what is the average population by landmass? What is the minimum population by landmass? What is the maximum population by landmass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Instantiate an object called `flag_means` that selects the `population` and groups it by `zone`, then by `landmass` and calculates the mean of the population.\n",
    "\n",
    "*Note: zone: Geographic quadrant, based on Greenwich and the Equator (1=NE, 2=SE, 3=SW, 4=NW)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Turn `flag_means` into a DataFrame with `zone` as the rows and `landmass` as the columns. You should be able to do this using one pandas method. Take note of the missing values in the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Group the entire `flags` dataset by `landmass` and compute the median of each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** How many countries are represented in each group if you group by `landmass` and then `zone`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating Over Groups\n",
    "\n",
    "The GroupBy object supports iteration, generating a sequence of 2-tuples containing the group name along with the chunk of data.\n",
    "\n",
    "Let's remind ourselves of our sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# view DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# reminder: this creates a DataFrameGroupBy object\n",
    "df.groupby('studio_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can iterate through this object to find the name and group data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# loop through object\n",
    "for name, group in df.groupby('studio_key'):\n",
    "    print(name)\n",
    "    print(group)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of multiple keys, the first element in the tuple will be a tuple of key values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# loop through object\n",
    "for (key1, key2), group in df.groupby(['studio_key', 'department_key']):\n",
    "    print(f'key1: {key1}')\n",
    "    print(f'key2: {key2}')\n",
    "    print(group)\n",
    "    print('----') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default `groupby` groups on axis=0, but you can group on any of the other axes. For example, we could group the columns of our example `df` here by `dtype` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# print data type and respective group data\n",
    "grouped = df.groupby(df.dtypes, axis=1)\n",
    "for dtype, group in grouped:\n",
    "    print(dtype)\n",
    "    print(group)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Column or Subset of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby studio_key, average of 'data1', returns Series\n",
    "df['data1'].groupby(df['studio_key']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntactic sugar for above\n",
    "df.groupby('studio_key')['data1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 'studio_key', average of data2, returns DataFrame\n",
    "df[['data2']].groupby(df['studio_key']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntactic sugar for above\n",
    "df.groupby('studio_key')[['data2']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially for large datasets, it may be desirable to aggregate only a few columns. For example, in the preceding dataset, to compute means for just the data2 column and get the result as a DataFrame, we could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped DataFram\n",
    "df.groupby(['studio_key', 'department_key'])[['data2']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped Series\n",
    "df.groupby(['studio_key', 'department_key'])['data2'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with Dictionaries and Series\n",
    "\n",
    "To see different ways to work with grouping, let's create a DataFrame of student grades that have taken two courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another sample DataFrame\n",
    "students = pd.DataFrame(np.random.randint(80,100,(5,5)),\n",
    "                       columns=[1,2,3,4,5],\n",
    "                       index=['Joe','Steve','Beth','Jim','Sue'])\n",
    "# add some NA values\n",
    "students.iloc[2:3,[1,2]] = np.nan \n",
    "\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we want to map course names to the specific quiz. We can do this with a mapping and then groupby this dictionary mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping\n",
    "mapping = {1:670,2:670,3:520,4:520,5:670,6:680}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the mapping to the groupby object\n",
    "by_column = students.groupby(mapping, axis=1)\n",
    "\n",
    "# summing by the grouped mapping, notice the unused mapping is OK\n",
    "by_column.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also work with Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Series of\n",
    "map_series = pd.Series(mapping)\n",
    "map_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass Series to groupby object\n",
    "students.groupby(map_series, axis=1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with Functions\n",
    "\n",
    "Any function passed as a group key will be called once per index value.\n",
    "\n",
    "As an example, let's say we wanted to group students based on how many letters were in their name and find their median score. (Why we would ever want to do this? Who knows. Just go along with me here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by index length (in this case student name)\n",
    "students.groupby(len).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's rename the columns\n",
    "students = students.rename(columns=mapping)\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a second key list\n",
    "key_list = ['MA','NY','NY','MA','NY']\n",
    "\n",
    "# groupby function, then by key_list\n",
    "students.groupby([len, key_list]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by Index Levels\n",
    "\n",
    "You can easily aggregate using one of the levels of a multi-index. Let's add a `gender` column to our `students` data and create a multi-index DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding gender column\n",
    "students['gender'] = ['M','M','F','M','F']\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating multi-index\n",
    "students = students.reset_index().set_index(['index','gender'])\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by 'gender' index and counting number of quizzes taken by gender\n",
    "students.groupby(level='gender').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Practice\n",
    "\n",
    "Try to perform the following tasks on the `flags` dataset. Then check your answers as I walk through the solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# let's remind oursleves of our DataFrame\n",
    "flags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** What is the sum of the `num_crosses` grouped by `religion`?\n",
    "\n",
    "*Note: religion: 0=Catholic, 1=Other Christian, 2=Muslim, 3=Buddhist, 4=Hindu, 5=Ethnic, 6=Marxist, 7=Others*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** What is the sum of `crescent` grouped by `religion`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** What are the total value counts of all the colors in `mainhue` grouped by `religion`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** What is the maximum `area` for each group that is grouped by `zone` and then `religion`? What is the minimum area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Let's try to determine if there are more colors or shapes on the country flags.\n",
    "1. Create a subset of the `flags` data and call it `flags_subset`. This subset should include the following attributes: 'red', 'green', 'blue', 'gold', 'white', 'black', 'orange', 'num_circles', 'num_crosses', 'num_saltires', 'num_sunstars', 'crescent',  and 'triangle'\n",
    "2. Create a dictionary that maps all colors to the string `color` and all shapes to the string `shape`\n",
    "3. Use the mapping dictionary from step 2 to calculate the sum of the colors and shapes for each instance.\n",
    "4. *Bonus:* Sum up all the colors and shapes for all instances to determine if there are more colors or shapes on all the flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Aggregation\n",
    "\n",
    "You can use aggregations of your own devising and additionally call any method that is also defined on the grouped object. \n",
    "\n",
    "Let's look at another simple example. First, let's create a similar DataFrame to our `students` that represents the grades of five quizzes these students received in one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another simple DataFrame\n",
    "quiz_df = pd.DataFrame(np.random.randint(70,100,(8,5)),\n",
    "                       columns=[1,2,3,4,5],\n",
    "                       index=['Joe','Steve','Beth','Jim','Sue','James','Amy','Monika'])\n",
    "\n",
    "# add a gender column for grouping\n",
    "quiz_df['gender'] = ['M','M','F','M','F','M','F','F']\n",
    "quiz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby gender\n",
    "grouped = quiz_df.groupby('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use agg and pass 'mean'\n",
    "# notice you pass this as a string\n",
    "grouped.agg('mean')\n",
    "\n",
    "# notice that this is the same as passing the following:\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the fun part. Let's say that you wanted to know the range of the top score and bottom score for each quiz broken down by gender. We can create our own custom function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple custom function\n",
    "def range_scores(arr):\n",
    "    return arr.max() - arr.min()\n",
    "\n",
    "# pass function to agg\n",
    "grouped.agg(range_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also pass the describe method to a grouped object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add another column that lists the student's level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df['level'] = ['Senior','Junior','Senior','Senior','Junior','Junior','Senior','Junior']\n",
    "quiz_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's add an average quiz score for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df['avg'] = quiz_df[[1,2,3,4,5]].mean(axis=1)\n",
    "quiz_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's group by student level and then by gender. We will select only the `avg` column and see what the mean score is for the respective groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby level and gender\n",
    "grouped = quiz_df.groupby(['level','gender'])\n",
    "\n",
    "# selecting only the avg column\n",
    "grouped_avg = grouped['avg']\n",
    "\n",
    "# aggregating the mean\n",
    "grouped_avg.agg('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above\n",
    "grouped['avg'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a list of functions or function names instead, you get back a DataFrame with column names taken from the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_avg.agg(['mean','std',range_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a list of functions and pass this list to `agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of functions\n",
    "functions = ['mean','std',range_scores]\n",
    "\n",
    "grouped_avg.agg(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change the name of the column when you aggregate like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_avg.agg([('Average', 'mean'), ('Std Dev', 'std'), ('Range', range_scores)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's say that we want to apply a different function to separate columns of the DataFrame. You can pass a dictionary like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg({1:'mean', 2:'median', 3:'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply (split-apply-combine)\n",
    "\n",
    "The most general-purpose GroupBy method is `apply`. `apply` splits the object being manipulated into pieces, invokes the passed function on each piece, and then attempts to concatenate the pieces together.\n",
    "\n",
    "Let's start by creating a new sample DataFrame of flights from Vienna to Charlotte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample flights data\n",
    "flights = pd.DataFrame({\n",
    "    'airline': ['Delta','Delta','Delta','Delta','Delta','United','United','United','United','Lufthansa','Lufthansa',\n",
    "                'Lufthansa','Lufthansa','Lufthansa','Lufthansa','British Airways','British Airways','British Airways'],\n",
    "    'price': np.random.randint(600,1000,18),\n",
    "    'time': np.random.randint(8,16,18)\n",
    "})\n",
    "\n",
    "flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a custom function that selects `n` rows with the lowest values in a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom function\n",
    "def best(df, n=3, column='price'):\n",
    "    return df.sort_values(by=column)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on full data\n",
    "best(flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's group by `airlines` and call `apply` with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.groupby('airline').apply(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add other arguments in the `apply` method. What if we wanted only the two shortest flights by airline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two shortest flights grouped by airline\n",
    "flights.groupby('airline').apply(best, n=2, column='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Practice\n",
    "\n",
    "Try to perform the following tasks on the `flags` dataset. Then check your answers as I walk through the solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Group the data by `zone` and determine the difference between the zone's largest area and its smallest area. Do this by creating a custom function and passing it to the `agg` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Add a new column called `pop_den` to the DataFrame that represents the respective country's population density. Population density is defined as the population divided by the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Group by `landmass` and determine the mean, median, standard deviation and range for the population density column. Call the columns 'Avg', 'Median', 'Std Dev' and 'Range' respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Grouping the data by landmass, what is the max number of bars for each group, the average number of stripes, and the median value for number of colors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "1. Create a custom function called `top` that returns the top 2 rows with the **largest** values in the `pop_den` column. \n",
    "2. Make sure that you do not include any rows with NaNs in the `pop_den` column.\n",
    "3. Setup your function arguments so that you can change the number of rows to show and which column to sort by.\n",
    "4. Group the `flags` data by `landmass` and use the apply function with your custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using the above custom function (`top`), return the top 3 rows with the highest `population` grouped by `zone`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "1. Create a second custom function called `bottom` that returns the 2 rows with the smallest values in the `pop_den` column. Do not include any rows with a `pop_den` of `0`.\n",
    "2. Group the `flags` data by `landmass` and use the apply function with your custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Pivot Tables and Cross-Tabulation\n",
    "\n",
    "A pivot table aggregates a table of data by one or more keys, arranging the data in a rectangle with some of the group keys along the rows and some along the columns. Pivot tables in Python with pandas are made possible through groupby combined with reshape operations utilizing hierarchical indexing.\n",
    "\n",
    "To show this, let's add a new column to our `flights` data that shows if the flight is in the morning or afternoon/evening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup list\n",
    "part_of_day = ['AM','PM']\n",
    "\n",
    "# use random choice to select AM/PM for each row\n",
    "time_of_day = np.random.choice(part_of_day,18)\n",
    "time_of_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column to data\n",
    "flights['time_of_day'] = time_of_day\n",
    "flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to compute a table of price and time averages arranged by airline and time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of price/time by airline/time of day\n",
    "flights.pivot_table(index=['airline','time_of_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose just a select column or group of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only price\n",
    "flights.pivot_table('price', index=['airline','time_of_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can compute the average price and time broken down by time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average price/time broken down by time of day\n",
    "flights.pivot_table(index=['airline'],columns='time_of_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you include `margins=True`, it will compute group statistics for all the data within a single tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include margins=True\n",
    "flights.pivot_table('price', index='airline', columns='time_of_day', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[flights['airline'] == 'British Airways']['price'].mean()\n",
    "flights[flights['time_of_day'] == 'AM']['price'].mean()\n",
    "flights['price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default function for a pivot table is `mean` although you can change it with the `aggfunc` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using count\n",
    "flights.pivot_table(['price'], index=['airline'], columns='time_of_day', margins=True, aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cross-tabulation (or crosstab) is a special case of a pivot table that computes group frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cross tab\n",
    "pd.crosstab(flights['airline'], flights['time_of_day'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Practice\n",
    "\n",
    "Try to perform the following tasks on the `flags` dataset. Then check your answers as I walk through the solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create a pivot table using the `flags` data. Group the rows by `landmass` and use `median` as the aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create a pivot table grouping by `religion` in the index and summing the `crescent`, `num_crosses`, and `num_saltires`  columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create a pivot table grouping by `religion` in the index and `zone` in the columns. Use the `sum` function and select the `crescent`, `num_crosses`, and `num_saltires` columns. Add a total for each row and for each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Notice that the above output should have a lot of NaNs in the rows. See the [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) to see how to compute the same pivot table but fill all NaNs with a `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using `crosstab`, compute the group frequencies for `landmass` vs `religion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Machine Learning Model\n",
    "\n",
    "Now that we learned about various aggregation and grouping operations, let's finish this module with a model to determine if we can predict a country's main religion based mostly on its flag's details.\n",
    "\n",
    "Please note that I do not expect you to understand the rest of this code. You will learn more about this in future classes. This is meant for motivation for what you can do with this data. See the last cell for the results.\n",
    "\n",
    "**Note:** If you attempt to run this code yourself, you will need to install `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# dropping name column as this provides no additional data\n",
    "flags = flags.drop('name', axis=1)\n",
    "\n",
    "# creating features and response\n",
    "X = flags.drop('religion', axis=1)\n",
    "y = flags[['religion']]\n",
    "\n",
    "# splitting data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of numeric columns\n",
    "num_col = ['area','population','num_bars','num_stripes','num_colors','num_circles','num_crosses',\n",
    "          'num_saltires','num_quarters','num_sunstars','pop_den'] \n",
    "\n",
    "X_train_num = X_train[num_col]\n",
    "\n",
    "# create pipeline for numeric columns to impute and scale data\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of numeric attributes\n",
    "num_attribs = list(X_train_num)\n",
    "\n",
    "# create list of attributes to be One-Hot-Encoded\n",
    "OHE_attribs = ['landmass','zone','language','mainhue','topleft_color','botright_color']\n",
    "\n",
    "# create full pipeline \n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('OHE', OneHotEncoder(), OHE_attribs),\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training and testing data through pipeline\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_prepared = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# just using mostly default values for random forest, no grid search\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf.fit(X_train_prepared, np.array(y_train).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor Generalization Errors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_preds = rf.predict(X_test_prepared)\n",
    "acc_score_forest = accuracy_score(y_test, y_preds)\n",
    "prec_score_forest = precision_score(y_test, y_preds, average='micro')\n",
    "recall_score_forest = recall_score(y_test, y_preds, average='micro')\n",
    "\n",
    "model_name = type(rf).__name__\n",
    "\n",
    "print(f'Model {model_name} | Accuracy: {acc_score_forest}')\n",
    "print(f'Model {model_name} | Precision: {prec_score_forest}')\n",
    "print(f'Model {model_name} | Recall: {recall_score_forest}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottom line was that we are able to predict with 69% accuracy a country's main religion based mostly on the details of its flag. This is not bad considering what little data we have to work with. \n",
    "\n",
    "Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
